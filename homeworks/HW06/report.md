# HW06 — Деревья решений и ансамбли

## 1. Описание задачи

Цель работы — изучить поведение деревьев решений и ансамблевых методов
(bagging, random forest, boosting) в задаче классификации, а также провести
честный ML-эксперимент с корректным разбиением данных, подбором гиперпараметров
и финальной оценкой качества моделей на тестовой выборке.

Особое внимание уделяется:
- контролю сложности моделей;
- сравнению одиночных моделей и ансамблей;
- выбору корректных метрик качества для несбалансированных данных;
- интерпретации лучшей модели.

---

## 2. Описание данных

Для эксперимента был выбран датасет **S06-hw-dataset-04.csv**.

Характеристики датасета:
- задача: бинарная классификация;
- таргет: `target`;
- присутствует сильный дисбаланс классов (fraud-like сценарий);
- количество признаков — большое, все признаки числовые;
- столбец `id` исключён из признаков.

Датасет является синтетическим и используется исключительно в учебных целях.

---

## 3. Первичный анализ данных (EDA)

В ходе первичного анализа были выполнены:
- просмотр первых строк (`head`);
- анализ структуры данных (`info`);
- расчёт базовых статистик (`describe`);
- анализ распределения целевой переменной.

Распределение таргета показало сильный дисбаланс классов, в связи с чем
использование одной лишь метрики accuracy является некорректным.
Для оценки качества моделей дополнительно использовались метрики **F1-score**
и **ROC-AUC**.

Пропусков в данных обнаружено не было.

---

## 4. Постановка ML-эксперимента

Данные были разделены на обучающую и тестовую выборки в пропорции 75% / 25%.

Параметры разбиения:
- `random_state = 42` — для воспроизводимости результатов;
- `stratify = y` — для сохранения исходного дисбаланса классов в обеих выборках.

Подбор гиперпараметров всех моделей выполнялся **только на train-выборке**
с использованием кросс-валидации.
Тестовая выборка использовалась ровно один раз — для финальной оценки качества.

---

## 5. Baseline-модели

В качестве baseline были рассмотрены две модели:

### 5.1 DummyClassifier

DummyClassifier с стратегией `most_frequent` показал крайне низкое качество,
что ожидаемо для сильно несбалансированного датасета.
Модель практически всегда предсказывает мажоритарный класс и не способна
выявлять объекты миноритарного класса.

### 5.2 Logistic Regression

Логистическая регрессия была обучена в пайплайне со StandardScaler
и с параметром `class_weight="balanced"`.

По сравнению с DummyClassifier качество существенно улучшилось,
однако модель всё ещё уступает ансамблевым методам,
что объясняется сложной нелинейной структурой данных.

---

## 6. Модели недели 6

В рамках работы были обучены и сравнены следующие модели:

### 6.1 Decision Tree

Использовалось дерево решений с контролем сложности
(`max_depth`, `min_samples_leaf`).
Подбор гиперпараметров выполнялся через GridSearchCV.

Контроль сложности позволил снизить переобучение,
однако одиночное дерево уступает ансамблям по качеству.

---

### 6.2 Random Forest

Random Forest был обучен как ансамбль деревьев решений
с дополнительной случайностью по объектам и признакам.

Подбор гиперпараметров включал:
- `max_depth`;
- `min_samples_leaf`.

Модель показала существенный прирост ROC-AUC и F1-score
по сравнению с одиночным деревом.

---

### 6.3 Gradient Boosting

Gradient Boosting обучался как последовательный ансамбль,
где каждое следующее дерево исправляет ошибки предыдущих.

Подбирались параметры:
- `learning_rate`;
- `max_depth`;
- `n_estimators`.

Данная модель показала **наилучшее качество** среди всех рассмотренных
по метрике ROC-AUC на тестовой выборке.

---

## 7. Сравнение моделей и метрики качества

Для всех моделей на тестовой выборке рассчитывались метрики:
- Accuracy;
- F1-score;
- ROC-AUC.

Основной метрикой выбора лучшей модели был выбран **ROC-AUC**,
так как датасет является сильно несбалансированным.

Лучшей моделью по итогам эксперимента оказался **Gradient Boosting**.

---

## 8. Интерпретация лучшей модели

Для лучшей модели была рассчитана **Permutation Importance**
на тестовой выборке.

Анализ важности признаков показал, что модель опирается на ограниченное число
наиболее информативных признаков, в то время как вклад остальных существенно ниже.
Это согласуется с ожиданиями для задач fraud-like типа,
где лишь часть признаков действительно несёт полезный сигнал.

---

## 9. Артефакты эксперимента

В папке `artifacts/` сохранены следующие результаты эксперимента:
- `metrics_test.json` — финальные метрики на тестовой выборке;
- `search_summaries.json` — лучшие гиперпараметры моделей;
- `best_model.joblib` — сохранённая лучшая модель;
- `best_model_meta.json` — метаданные лучшей модели;
- папка `figures/` с диагностическими графиками (ROC-кривая и confusion matrix).

---

## 10. Выводы

В ходе работы было показано, что:
- одиночные модели плохо справляются с задачами на сильно несбалансированных данных;
- ансамблевые методы (Random Forest и Boosting) дают существенный прирост качества;
- Gradient Boosting оказался наиболее эффективным решением в данной задаче;
- использование корректных метрик (F1, ROC-AUC) критично для адекватной оценки моделей;
- честная постановка ML-эксперимента позволяет избежать переоценки качества.

Поставленные в рамках домашнего задания цели были достигнуты.
